# Project Website
This is our website for our chain of debate project by Kovidh Jain, Liam May, and Omer Abbas.

## Report
We wrote an extensive report on how using chain of debate-where models argue with each other before producing a final response-can produce modest improvements in performance metrics such as precision, recall, and F1. The report is linked below.

[View Report](https://github.com/Omer1BC/LLMProject/blob/main/Chain_of_Debate__A_Multi_Agent_Framework_for_Misinformation_Detection.pdf)  


## Slides & Video
Our team also presented slides on the issue covering the highlights of our findings. The recording of our slide presentation is provided in a video with and a small demo that gives an example of how the debate plays for a particular article.

[View Slides](https://github.com/Omer1BC/LLMProject/blob/main/Chain_of_Debate__A_Multi_Agent_Framework_for_Misinformation_Detection.pdf)  
[Watch the Demo](https://www.youtube.com/watch?v=BfJ4w71tdrE)  
[Watch the Recording](https://www.youtube.com/watch?v=UkqEEMxqT9g&t=421s)


## Code
There are 2 portions to the project: the main debate algorithm and benchmarks we used for basic classifiers like Naive Bayes, Logistic Regression, and Random Forest. The details for reproducing the code are found in the readmes for each part. Note that we wanted to additionally use the FEVER dataset, but this was put on pause until we could find some way get unbanned from scraping DuckDuckGo since we sent extensive requests for sources.

[Instructions for Chain of Debate](https://github.com/Omer1BC/LLMProject/tree/main/code/chain-of-debate/informed-llm)  
[Instructions for Benchmarks](https://github.com/Omer1BC/LLMProject/tree/main/code/benchmarks)  

